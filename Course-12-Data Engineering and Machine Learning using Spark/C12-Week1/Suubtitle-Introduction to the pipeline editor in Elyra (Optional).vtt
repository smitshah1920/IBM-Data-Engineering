WEBVTT

1
00:00:00.000 --> 00:00:04.140
Today I want to walk you through
the pipeline editor of a lira.

2
00:00:04.140 --> 00:00:05.833
And as you can see here,

3
00:00:05.833 --> 00:00:10.770
we are running a lira in communities
in the IBM communities ancient.

4
00:00:10.770 --> 00:00:16.054
But you can run a lira in any
environment in docker on your laptop or

5
00:00:16.054 --> 00:00:19.240
any communities environment.

6
00:00:19.240 --> 00:00:22.340
So let's have a look at what we have here.

7
00:00:22.340 --> 00:00:26.854
So I will cover two things which
aren't that important to me first, but

8
00:00:26.854 --> 00:00:31.144
then I will directly dive into
the pipeline editor because a lira has

9
00:00:31.144 --> 00:00:35.240
a couple of more functions
than only the pipeline editor.

10
00:00:35.240 --> 00:00:37.950
So here we see, one thing.

11
00:00:37.950 --> 00:00:41.611
This is get extension.

12
00:00:41.611 --> 00:00:45.940
So let's actually go into a Git
repository, which I have cloned.

13
00:00:45.940 --> 00:00:51.510
And then you see here you are actually
seeing the untracked files and

14
00:00:51.510 --> 00:00:57.091
you can stage your changes and
you can commit and push and pull here.

15
00:00:57.091 --> 00:01:00.370
You can pull and
here you can push and all that stuff.

16
00:01:00.370 --> 00:01:06.470
Okay, then another thing is you have
here TOC, Table of content extension.

17
00:01:06.470 --> 00:01:13.221
So let's just create a new notebook And
then create a markdown cell.

18
00:01:13.221 --> 00:01:16.861
And let's say here a section one.

19
00:01:18.140 --> 00:01:23.104
And then let's create
another markdown set and

20
00:01:23.104 --> 00:01:26.940
say Subject to Subsection one.

21
00:01:26.940 --> 00:01:29.740
Section one.

22
00:01:29.740 --> 00:01:33.150
Okay?
So if you know how to go to the T O C.

23
00:01:33.150 --> 00:01:38.440
You see here that you have
actually that you see here.

24
00:01:38.440 --> 00:01:41.510
And also you can automatically
create a number.

25
00:01:41.510 --> 00:01:43.240
That's quite handy.

26
00:01:43.240 --> 00:01:47.754
Then another thing we have here code
snippets and of course you can import

27
00:01:47.754 --> 00:01:52.140
code snippet libraries for
different programming languages.

28
00:01:52.140 --> 00:01:56.915
And it then comes very handy to
just drag and drop the coat,

29
00:01:56.915 --> 00:02:03.349
snap snippets in to the notebook and
without a necessity to actually search for

30
00:02:03.349 --> 00:02:09.130
the code snippets then what we see
here is configuration of run times.

31
00:02:09.130 --> 00:02:16.570
I will come back to that later and also
here a configuration of runtime images.

32
00:02:16.570 --> 00:02:20.462
Just keep in mind That you
have those two Taps here and

33
00:02:20.462 --> 00:02:24.940
then of course the last one
is the extension manager.

34
00:02:24.940 --> 00:02:28.940
Okay, so
now let's start with the pipeline editor.

35
00:02:28.940 --> 00:02:31.551
The pipeline editor is
actually pretty cool.

36
00:02:31.551 --> 00:02:35.356
So you can just create a new pipeline and

37
00:02:35.356 --> 00:02:40.680
the pipeline you can then
push to an execution engine.

38
00:02:40.680 --> 00:02:46.940
So either you have local execution or you
can use Q flow or airflow at the moment.

39
00:02:46.940 --> 00:02:50.125
And if you use the generic
pipeline editor,

40
00:02:50.125 --> 00:02:53.998
you can push to local execution
to cuba and airflow But

41
00:02:53.998 --> 00:02:59.030
we have here two specific to
the execution engine pipeline editors.

42
00:02:59.030 --> 00:03:03.960
And that actually allows for
using pipeline.

43
00:03:03.960 --> 00:03:05.691
Ancient specific components.

44
00:03:05.691 --> 00:03:07.940
So let me just illustrate that.

45
00:03:07.940 --> 00:03:14.238
So you have here on the left hand side,
a list of generic components which are for

46
00:03:14.238 --> 00:03:18.186
example, jupiter notebooks or
python scripts or

47
00:03:18.186 --> 00:03:22.431
our scripts which you can drag and
drop to the canvas.

48
00:03:22.431 --> 00:03:27.951
But now here we are starting to
add cube flow specific components.

49
00:03:27.951 --> 00:03:29.450
Let's have a look what we have here.

50
00:03:29.450 --> 00:03:34.040
So that's a notebook that's of
course same as we have here.

51
00:03:34.040 --> 00:03:37.840
But then we have here, for
example a filter component.

52
00:03:37.840 --> 00:03:40.820
Of course, it will have some more
components in the near future.

53
00:03:40.820 --> 00:03:45.181
But let's have a look
at our flow pipeline.

54
00:03:45.181 --> 00:03:47.721
It it also we have a couple
of more components already.

55
00:03:47.721 --> 00:03:54.163
So best operator, email operator
to send emails, HTTP operator and

56
00:03:54.163 --> 00:04:01.440
spark SQL operator where you can
submit SQL statements against sparks.

57
00:04:01.440 --> 00:04:05.905
Also here, spark submit where you
can submit spark applications

58
00:04:05.905 --> 00:04:10.541
against the spark cluster and
then a slack connector or something.

59
00:04:10.541 --> 00:04:16.761
Okay, but now let's go back to
the generic pipeline editor.

60
00:04:18.640 --> 00:04:23.107
So as you are used to you can drag and
drop notebooks, python, scripts and

61
00:04:23.107 --> 00:04:27.661
scripts on top of the canvas and then
later push it to the execution engine.

62
00:04:29.140 --> 00:04:33.816
And the cool thing is if you
have a component library

63
00:04:33.816 --> 00:04:38.300
then of course a lot of
work is being done for you.

64
00:04:38.300 --> 00:04:42.268
Okay, so let's consider, for example,

65
00:04:42.268 --> 00:04:47.781
here in the input section,
a postgres square connector and

66
00:04:47.781 --> 00:04:52.080
why this is red is because
you have to tell a lira

67
00:04:52.080 --> 00:04:57.440
which runtime image it has
to sign to this component.

68
00:04:57.440 --> 00:05:02.775
That means this component here is
running in its own container and

69
00:05:02.775 --> 00:05:06.849
this container of course
needs a runtime image and

70
00:05:06.849 --> 00:05:11.330
you can actually configure
those random images here.

71
00:05:11.330 --> 00:05:15.340
Okay, so
this is the anaconda image you see here.

72
00:05:15.340 --> 00:05:18.420
That's the image name,
pull policy and so on.

73
00:05:18.420 --> 00:05:21.361
And of course you can also
connect to other registries.

74
00:05:23.840 --> 00:05:28.780
So let's go back to the editor and
what you see here is the parameters to

75
00:05:28.780 --> 00:05:33.540
that component are automatically
generated in this UI here.

76
00:05:33.540 --> 00:05:36.401
So this is a post rest connector.

77
00:05:36.401 --> 00:05:40.524
That means it pulls data from
a post grad school database and

78
00:05:40.524 --> 00:05:44.977
of course you need the host name,
the database name, the user,

79
00:05:44.977 --> 00:05:48.550
the passport support,
the actual SQL statement.

80
00:05:48.550 --> 00:05:52.370
You want to run against the post
grad school database And

81
00:05:52.370 --> 00:05:57.590
also some temporary directory and
here also the name of the output CSB five.

82
00:05:57.590 --> 00:06:00.340
The component has to start the fire too.

83
00:06:00.340 --> 00:06:05.329
And then of course you can
attach other components of for

84
00:06:05.329 --> 00:06:10.639
example if you want to pull data
from a Postgres database and

85
00:06:10.639 --> 00:06:16.240
you want to upload this
directly to cloud objects door.

86
00:06:16.240 --> 00:06:17.161
It's very easy.

87
00:06:18.240 --> 00:06:22.471
So you just then specify here
the properties of the cloud object store.

88
00:06:22.471 --> 00:06:27.600
So access key, secret access key,
endpoint, bucket name and so on and so on.

89
00:06:27.600 --> 00:06:30.431
And the cool thing is it works
with IBM cloud object store.

90
00:06:30.431 --> 00:06:33.731
It works with amazon S three and
with mini mini yo.

91
00:06:33.731 --> 00:06:38.440
And every S three compliant
cloud object store.

92
00:06:38.440 --> 00:06:42.011
Yeah, that's more or less it for now.

93
00:06:42.011 --> 00:06:45.273
So if you now doctor to
click on one component,

94
00:06:45.273 --> 00:06:49.877
the underlying trumpeter notebook
opens and you see here that's

95
00:06:49.877 --> 00:06:55.081
designed by contract configuration
of the interface of the components.

96
00:06:55.081 --> 00:06:59.303
So you have different
environment variable names and

97
00:06:59.303 --> 00:07:03.450
those are actually set and
injected through a lira.

98
00:07:03.450 --> 00:07:09.281
So if you go back to the pipeline, you see
here all those parameters are extracted

99
00:07:09.281 --> 00:07:14.426
for you have to set those and they
are then injected into this notebook so

100
00:07:14.426 --> 00:07:18.670
all those parameters set and
then they are actually used.

101
00:07:18.670 --> 00:07:23.394
So it's pretty straightforward,
you just connect to the database and

102
00:07:23.394 --> 00:07:28.433
you execute SQL query against the database
and then you just write data frame

103
00:07:28.433 --> 00:07:34.280
you obtain from query to Assisi fire, I
mean That's work off around 5-10 minutes.

104
00:07:34.280 --> 00:07:38.808
If you search for the code snippets and
put it together but that way,

105
00:07:38.808 --> 00:07:43.733
first of all it's tested, it's like
opinionated and on the other hand,

106
00:07:43.733 --> 00:07:48.421
if you just drag and drop it,
you don't have to code no, you still have

107
00:07:48.421 --> 00:07:53.519
direct access to the underlying source
code, you can modify it if you like.

108
00:07:53.519 --> 00:07:58.301
But if you don't you have just a pure
no code experience here Okay, and

109
00:07:58.301 --> 00:08:03.329
it's fully open source and the really,
really cool thing here is if we say

110
00:08:03.329 --> 00:08:08.517
run it will fail of course because all
the parameters are not set, but just to

111
00:08:08.517 --> 00:08:14.232
illustrate, you can have a local execution
but we can just send it to communities.

112
00:08:14.232 --> 00:08:19.257
So too pure for Pipelines, it gets
packaged up and sent to communities and

113
00:08:19.257 --> 00:08:24.119
also this cube flu instance, he is
running the IBM cloud to see that here

114
00:08:24.119 --> 00:08:27.441
at the europe but
it can run anywhere of course and

115
00:08:27.441 --> 00:08:31.169
you directly get the lock,
so every execution stage,

116
00:08:31.169 --> 00:08:36.060
which respect by one single notebook
is running inside the container.

117
00:08:36.060 --> 00:08:40.363
Those containers, of course
running in a pot in kubernetes and

118
00:08:40.363 --> 00:08:44.908
do directly get the standard out
streamed and of course here we have

119
00:08:44.908 --> 00:08:50.300
an exception because we didn't set
variables but anyway this is how it works.

120
00:08:50.300 --> 00:08:55.347
In addition,
if you don't want to use the low code,

121
00:08:55.347 --> 00:09:03.540
no quote style, you can still chest use
a pure python based script or notebook.

122
00:09:03.540 --> 00:09:08.859
So the library, by the way, this library
is called claimed component library for

123
00:09:08.859 --> 00:09:13.022
a I machine learning and data science,
no component library for

124
00:09:13.022 --> 00:09:17.670
a I imagine learning each day to sign so
I will just cover everything.

125
00:09:17.670 --> 00:09:21.739
You can use this library
also without a lira and

126
00:09:21.739 --> 00:09:27.266
without UI the only thing to use
a component is such a call here so

127
00:09:27.266 --> 00:09:33.736
you have Ipython and then you address
the component which is a notebook and

128
00:09:33.736 --> 00:09:38.119
then you can pass all
the available parameters and

129
00:09:38.119 --> 00:09:43.640
the way how this is done is
basically through this loop.

130
00:09:43.640 --> 00:09:49.986
I have already externalized this from
the notebook but just to illustrate here,

131
00:09:49.986 --> 00:09:54.375
we are just passing all
the environment variables which

132
00:09:54.375 --> 00:09:59.509
are sorry the arguments which have
been passed to the notebook and

133
00:09:59.509 --> 00:10:05.430
then we just use the exact function of
python to set this as an environment.

134
00:10:05.430 --> 00:10:08.340
Sorry as a variable.

135
00:10:08.340 --> 00:10:09.240
Okay.

136
00:10:09.240 --> 00:10:15.530
And then that's basically also you can
use this library from anywhere and

137
00:10:15.530 --> 00:10:22.326
then finally that's just one thing I want
to mention, we have created C three,

138
00:10:22.326 --> 00:10:28.008
this is claimed component compiler
which takes such a notebook and

139
00:10:28.008 --> 00:10:35.350
creates a cube flow pipeline component for
you and those get uploaded to ML exchange.

140
00:10:35.350 --> 00:10:41.401
So that means you can create your
components by simply creating a trumpeter

141
00:10:41.401 --> 00:10:46.589
notebook and you see three sort
of claimed component compiler,

142
00:10:46.589 --> 00:10:50.440
which creates a huge component out of you.

143
00:10:50.440 --> 00:10:53.214
This you can upload two ML exchange and

144
00:10:53.214 --> 00:10:59.340
then you have it in a repository where
you can also search for the components.

145
00:10:59.340 --> 00:11:03.451
And later on you can use those
components in any cube flow environment.

146
00:11:03.451 --> 00:11:10.440
So in pure cube flow or in the IBM Watson
pipeline stool or in the library itself.

147
00:11:10.440 --> 00:11:13.310
Okay, so
I hope this makes it a bit more clear.

148
00:11:13.310 --> 00:11:17.910
And if you have any questions, just post
them to the forum or the comment section.

149
00:11:17.910 --> 00:11:18.520
Thanks a lot.

150
00:11:18.520 --> 00:11:19.020
Bye.
# [IBM-Data-Engineering Professional Certificate]([url](https://www.coursera.org/professional-certificates/ibm-data-engineer))

The IBM Data Engineering Professional Certificate is a comprehensive program designed to equip aspirants with the skills and knowledge needed to excel in the field of data engineering. This certificate program, It covers a wide range of topics related to data management, data processing, and data transformation. Participant gains practical experience in using various tools, technologies, and methodologies commonly used in the data engineering industry.

The curriculum of the IBM Data Engineering Professional Certificate covers key areas such as data integration, data warehousing, ETL (Extract, Transform, Load) processes, data pipelines, and data governance. It offers a combination of theoretical concepts and hands-on exercises, enabling learner to understand the theoretical foundations while also applying their skills in real-world scenarios.

Throughout the program, participants work on projects that mirror real data engineering challenges. These projects enable learners to develop a portfolio showcasing their ability to design, implement, and manage data workflows, work with structured and unstructured data, and leverage cloud-based platforms for data processing and storage. By completing these projects, participants demonstrate their proficiency in data engineering practices, which is a valuable asset for pursuing careers in data engineering roles.

By obtaining the IBM Data Engineering Professional Certificate, learners validate their expertise in the domain of data engineering and enhance their prospects for career advancement or transition into roles that involve managing and optimizing data pipelines, ensuring data quality, and contributing to data-driven decision-making within organizations.

## Applied Learning Project

Throughout this Professional Certificate, you will complete hands-on labs and projects to help you gain practical experience with Python, SQL, Relational Databases, NoSQL Databases, Apache Spark, building a data pipeline, managing a database and working with data in a data warehouse.

At the end, you will complete a Capstone Project that applies what you have learned to a real-world inspired scenario that requires you to design, deploy and manage an end-to-end data engineering platform consisting of various Relational (Transactional Data Warehousing), NoSQL & Big Data repositories as well as data piplelines to connect them.

## There are 13 courses throughout the specialization and a capstone project at the end:

1.Introduction to Data Engineer <br>
2.Python for Data Science, AI & Development <br>
3.Python Project for Data Engineer <br>
4.Introduction to Relational Databases (RDBMS) <br>
5.Databases and SQL for Data Science with Python <br>
6.Hands-on Introduction to Linux Commands and Shell Scripting <br>
7.Relational Database Administration (DBA) <br>
8.ETL and Data Pipelines with Shell, Airflow and Kafka <br>
9.Getting Started with Data Warehousing and BI Analytics <br>
10.Introduction to NoSQL Databases <br>
11.Introduction to Big Data with Spark and Hadoop <br>
12.Data Engineering and Machine Learning using Spark <br>
13.Data Engineering Capstone Project <br>

## Tools and Technologies
OLTP database - MySQL <br>
NoSql database - MongoDB <br>
Production Data warehouse – DB2 on Cloud <br>
Staging - Data warehouse – PostgreSQL <br>
Big data platform - Hadoop <br>
Big data analytics platform – Spark <br>
Business Intelligence Dashboard - IBM Cognos Analytics <br>
Data Pipelines - Apache Airflow <br>

![image](https://github.com/smitshah1920/IBM-Data-Engineering/assets/116938231/de69d4f0-4b72-49eb-8eef-e8e09b9fa762)

